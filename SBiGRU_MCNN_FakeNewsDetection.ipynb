{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SBiGRU-MCNN: Hybrid Context-Aware Fake News Detection\n",
    "\n",
    "Bu notebook, **\"The Power of Context: A Novel Hybrid Context-Aware Fake News Detection Approach\"** makalesindeki mimariyi LIAR dataset üzerinde implemente eder.\n",
    "\n",
    "## Mimari\n",
    "- **BERT + Multichannel CNN:** Metin içeriğini işler (statement + auxiliary text)\n",
    "- **Stacked BiGRU:** Sayısal özellikleri işler (speaker credit history)\n",
    "- **Concatenation + Sigmoid:** Binary classification\n",
    "\n",
    "## Dataset\n",
    "- **LIAR Dataset** (William Yang Wang, 2017)\n",
    "- Train: ~10,240 samples\n",
    "- Test: ~1,267 samples\n",
    "- [Kaggle Link](https://www.kaggle.com/datasets/msudhan/liar-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if needed)\n",
    "# !pip install transformers torch pandas scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths - Update these according to your setup\n",
    "TRAIN_PATH = './data/train.tsv'\n",
    "TEST_PATH = './data/test.tsv'\n",
    "MODEL_SAVE_PATH = './models/sbigru_mcnn.pth'\n",
    "\n",
    "# Hyperparameters\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 16\n",
    "MAX_EPOCHS = 15\n",
    "LEARNING_RATE = 2e-5\n",
    "DROPOUT = 0.5\n",
    "PATIENCE = 3  # Early stopping patience\n",
    "\n",
    "# Model config\n",
    "BERT_MODEL = 'bert-base-uncased'\n",
    "MCNN_FILTERS = 128\n",
    "MCNN_KERNEL_SIZES = [3, 4, 5]\n",
    "BIGRU_HIDDEN_DIM = 50\n",
    "BIGRU_NUM_LAYERS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names for LIAR dataset\n",
    "column_names = [\n",
    "    'id', 'label', 'statement', 'subject', 'speaker', 'job_title',\n",
    "    'state_info', 'party_affiliation', 'barely_true_counts', 'false_counts',\n",
    "    'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context'\n",
    "]\n",
    "\n",
    "# Load data\n",
    "df_train = pd.read_csv(TRAIN_PATH, sep='\\t', header=None, names=column_names)\n",
    "df_test = pd.read_csv(TEST_PATH, sep='\\t', header=None, names=column_names)\n",
    "\n",
    "print(f\"Train size: {df_train.shape}\")\n",
    "print(f\"Test size: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning - remove rows with missing critical values\n",
    "critical_columns = ['statement', 'speaker', 'barely_true_counts', 'false_counts', \n",
    "                    'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts']\n",
    "\n",
    "df_train = df_train.dropna(subset=critical_columns)\n",
    "df_test = df_test.dropna(subset=critical_columns)\n",
    "\n",
    "print(f\"After cleaning - Train: {len(df_train)}, Test: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary label conversion\n",
    "# Real (1): true, mostly-true, half-true\n",
    "# Fake (0): barely-true, false, pants-fire\n",
    "\n",
    "def convert_to_binary(label):\n",
    "    real_labels = ['true', 'mostly-true', 'half-true']\n",
    "    return 1 if label in real_labels else 0\n",
    "\n",
    "df_train['binary_label'] = df_train['label'].apply(convert_to_binary)\n",
    "df_test['binary_label'] = df_test['label'].apply(convert_to_binary)\n",
    "\n",
    "print(\"Train Label Distribution:\")\n",
    "print(df_train['binary_label'].value_counts())\n",
    "print(f\"\\nReal ratio: {df_train['binary_label'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preparation - combine statement with auxiliary information\n",
    "def prepare_text_input(row):\n",
    "    statement = str(row['statement']) if pd.notna(row['statement']) else \"\"\n",
    "    speaker = str(row['speaker']) if pd.notna(row['speaker']) else \"\"\n",
    "    job_title = str(row['job_title']) if pd.notna(row['job_title']) else \"\"\n",
    "    party = str(row['party_affiliation']) if pd.notna(row['party_affiliation']) else \"\"\n",
    "    state = str(row['state_info']) if pd.notna(row['state_info']) else \"\"\n",
    "    subject = str(row['subject']) if pd.notna(row['subject']) else \"\"\n",
    "    context = str(row['context']) if pd.notna(row['context']) else \"\"\n",
    "    \n",
    "    combined_text = f\"{statement} [SEP] Speaker: {speaker} [SEP] Job: {job_title} [SEP] Party: {party} [SEP] State: {state} [SEP] Subject: {subject} [SEP] Context: {context}\"\n",
    "    return combined_text\n",
    "\n",
    "df_train['text_input'] = df_train.apply(prepare_text_input, axis=1)\n",
    "df_test['text_input'] = df_test.apply(prepare_text_input, axis=1)\n",
    "\n",
    "print(\"Sample text input:\")\n",
    "print(df_train['text_input'].iloc[0][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features - speaker credit history\n",
    "numerical_columns = [\n",
    "    'barely_true_counts', 'false_counts', 'half_true_counts',\n",
    "    'mostly_true_counts', 'pants_on_fire_counts'\n",
    "]\n",
    "\n",
    "for col in numerical_columns:\n",
    "    df_train[col] = pd.to_numeric(df_train[col], errors='coerce').fillna(0)\n",
    "    df_test[col] = pd.to_numeric(df_test[col], errors='coerce').fillna(0)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "numerical_features_train = scaler.fit_transform(df_train[numerical_columns])\n",
    "numerical_features_test = scaler.transform(df_test[numerical_columns])\n",
    "\n",
    "for i, col in enumerate(numerical_columns):\n",
    "    df_train[f'{col}_scaled'] = numerical_features_train[:, i]\n",
    "    df_test[f'{col}_scaled'] = numerical_features_test[:, i]\n",
    "\n",
    "print(f\"Numerical features shape: {numerical_features_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL)\n",
    "print(f\"Tokenizer loaded: {BERT_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length, numerical_columns_scaled):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.numerical_columns = numerical_columns_scaled\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        \n",
    "        text = str(row['text_input'])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        numerical_features = torch.tensor(\n",
    "            [row[col] for col in self.numerical_columns],\n",
    "            dtype=torch.float32\n",
    "        )\n",
    "        \n",
    "        label = torch.tensor(row['binary_label'], dtype=torch.float32)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'numerical_features': numerical_features,\n",
    "            'label': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns_scaled = [f'{col}_scaled' for col in numerical_columns]\n",
    "\n",
    "train_dataset = FakeNewsDataset(df_train, tokenizer, MAX_LENGTH, numerical_columns_scaled)\n",
    "test_dataset = FakeNewsDataset(df_test, tokenizer, MAX_LENGTH, numerical_columns_scaled)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultichannelCNN(nn.Module):\n",
    "    \"\"\"Multichannel CNN for processing BERT outputs with different kernel sizes.\"\"\"\n",
    "    \n",
    "    def __init__(self, bert_hidden_size=768, num_filters=128, kernel_sizes=[3, 4, 5], dropout=0.5):\n",
    "        super(MultichannelCNN, self).__init__()\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=bert_hidden_size, out_channels=num_filters, kernel_size=ks)\n",
    "            for ks in kernel_sizes\n",
    "        ])\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output_dim = num_filters * len(kernel_sizes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len, hidden_size]\n",
    "        x = x.permute(0, 2, 1)  # [batch_size, hidden_size, seq_len]\n",
    "        \n",
    "        conv_outputs = []\n",
    "        for conv in self.convs:\n",
    "            conv_out = F.relu(conv(x))\n",
    "            pooled = F.max_pool1d(conv_out, conv_out.size(2)).squeeze(2)\n",
    "            conv_outputs.append(pooled)\n",
    "        \n",
    "        concatenated = torch.cat(conv_outputs, dim=1)\n",
    "        return self.dropout(concatenated)\n",
    "\n",
    "\n",
    "class StackedBiGRU(nn.Module):\n",
    "    \"\"\"Stacked Bidirectional GRU for processing numerical features.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=5, hidden_dim=50, num_layers=2, dropout=0.5):\n",
    "        super(StackedBiGRU, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_projection = nn.Linear(1, hidden_dim)\n",
    "        \n",
    "        self.bigru = nn.GRU(\n",
    "            input_size=hidden_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output_dim = hidden_dim * 2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, num_features]\n",
    "        x = x.unsqueeze(2)  # [batch_size, num_features, 1]\n",
    "        x = self.input_projection(x)  # [batch_size, num_features, hidden_dim]\n",
    "        \n",
    "        output, hidden = self.bigru(x)\n",
    "        final_hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
    "        return self.dropout(final_hidden)\n",
    "\n",
    "\n",
    "class SBiGRU_MCNN(nn.Module):\n",
    "    \"\"\"Hybrid model combining BERT+mCNN for text and sBiGRU for numerical features.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        bert_model_name='bert-base-uncased',\n",
    "        num_numerical_features=5,\n",
    "        mcnn_num_filters=128,\n",
    "        mcnn_kernel_sizes=[3, 4, 5],\n",
    "        bigru_hidden_dim=50,\n",
    "        bigru_num_layers=2,\n",
    "        dropout=0.5\n",
    "    ):\n",
    "        super(SBiGRU_MCNN, self).__init__()\n",
    "        \n",
    "        # BERT\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.bert_hidden_size = self.bert.config.hidden_size\n",
    "        \n",
    "        # mCNN\n",
    "        self.mcnn = MultichannelCNN(\n",
    "            bert_hidden_size=self.bert_hidden_size,\n",
    "            num_filters=mcnn_num_filters,\n",
    "            kernel_sizes=mcnn_kernel_sizes,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # sBiGRU\n",
    "        self.sbigru = StackedBiGRU(\n",
    "            input_dim=num_numerical_features,\n",
    "            hidden_dim=bigru_hidden_dim,\n",
    "            num_layers=bigru_num_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        combined_dim = self.mcnn.output_dim + self.sbigru.output_dim\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(combined_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, numerical_features):\n",
    "        # BERT + mCNN\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        bert_sequence_output = bert_output.last_hidden_state\n",
    "        mcnn_output = self.mcnn(bert_sequence_output)\n",
    "        \n",
    "        # sBiGRU\n",
    "        sbigru_output = self.sbigru(numerical_features)\n",
    "        \n",
    "        # Concatenation & Classification\n",
    "        combined = torch.cat((mcnn_output, sbigru_output), dim=1)\n",
    "        logits = self.classifier(combined)\n",
    "        \n",
    "        return logits.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = SBiGRU_MCNN(\n",
    "    bert_model_name=BERT_MODEL,\n",
    "    num_numerical_features=5,\n",
    "    mcnn_num_filters=MCNN_FILTERS,\n",
    "    mcnn_kernel_sizes=MCNN_KERNEL_SIZES,\n",
    "    bigru_hidden_dim=BIGRU_HIDDEN_DIM,\n",
    "    bigru_num_layers=BIGRU_NUM_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping to prevent overfitting.\"\"\"\n",
    "    \n",
    "    def __init__(self, patience=3, min_delta=0.001, mode='max'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "        \n",
    "    def __call__(self, score, model):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict().copy()\n",
    "        elif self._is_improvement(score):\n",
    "            self.best_score = score\n",
    "            self.best_model_state = model.state_dict().copy()\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                \n",
    "    def _is_improvement(self, score):\n",
    "        if self.mode == 'max':\n",
    "            return score > self.best_score + self.min_delta\n",
    "        return score < self.best_score - self.min_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, criterion, device, max_grad_norm=1.0):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        numerical_features = batch['numerical_features'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask, numerical_features)\n",
    "        \n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        \n",
    "        preds = (torch.sigmoid(logits) >= 0.5).float()\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return total_loss / len(dataloader), accuracy_score(all_labels, all_preds)\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels, all_probs = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            numerical_features = batch['numerical_features'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            logits = model(input_ids, attention_mask, numerical_features)\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs >= 0.5).float()\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / len(dataloader),\n",
    "        'accuracy': accuracy_score(all_labels, all_preds),\n",
    "        'precision': precision_score(all_labels, all_preds, zero_division=0),\n",
    "        'recall': recall_score(all_labels, all_preds, zero_division=0),\n",
    "        'f1': f1_score(all_labels, all_preds, zero_division=0),\n",
    "        'fake_precision': precision_score(all_labels, all_preds, pos_label=0, zero_division=0),\n",
    "        'fake_recall': recall_score(all_labels, all_preds, pos_label=0, zero_division=0),\n",
    "        'fake_f1': f1_score(all_labels, all_preds, pos_label=0, zero_division=0),\n",
    "        'predictions': all_preds,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class weights for imbalanced data\n",
    "n_fake = (df_train['binary_label'] == 0).sum()\n",
    "n_real = (df_train['binary_label'] == 1).sum()\n",
    "pos_weight = torch.tensor([0.85]).to(device)  # Tuned value\n",
    "\n",
    "# Loss, optimizer, scheduler\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=0.01)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=1)\n",
    "early_stopping = EarlyStopping(patience=PATIENCE, mode='max')\n",
    "\n",
    "print(f\"Optimizer: AdamW (lr={LEARNING_RATE})\")\n",
    "print(f\"Loss: BCEWithLogitsLoss (pos_weight={pos_weight.item()})\")\n",
    "print(f\"Early Stopping: patience={PATIENCE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_acc': [], 'val_f1': [],\n",
    "    'val_fake_f1': [], 'lr': []\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING STARTED\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch+1}/{MAX_EPOCHS}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    \n",
    "    # Evaluate\n",
    "    val_results = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    # Current LR\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_results['loss'])\n",
    "    history['val_acc'].append(val_results['accuracy'])\n",
    "    history['val_f1'].append(val_results['f1'])\n",
    "    history['val_fake_f1'].append(val_results['fake_f1'])\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_results['loss']:.4f} | Val Acc: {val_results['accuracy']:.4f}\")\n",
    "    print(f\"Val F1 (Real): {val_results['f1']:.4f} | Val F1 (Fake): {val_results['fake_f1']:.4f}\")\n",
    "    print(f\"LR: {current_lr:.2e} | Time: {elapsed:.2f}s\")\n",
    "    \n",
    "    # Scheduler & Early Stopping\n",
    "    scheduler.step(val_results['f1'])\n",
    "    early_stopping(val_results['f1'], model)\n",
    "    \n",
    "    if early_stopping.best_score == val_results['f1']:\n",
    "        print(f\"*** New best model! F1: {val_results['f1']:.4f} ***\")\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"\\nEarly stopping triggered after {epoch+1} epochs.\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(f\"Best Validation F1: {early_stopping.best_score:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(early_stopping.best_model_state)\n",
    "\n",
    "# Final evaluation\n",
    "final_results = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL TEST RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nOverall Metrics:\")\n",
    "print(f\"  Accuracy:  {final_results['accuracy']:.4f}\")\n",
    "print(f\"\\nReal (1) Class:\")\n",
    "print(f\"  Precision: {final_results['precision']:.4f}\")\n",
    "print(f\"  Recall:    {final_results['recall']:.4f}\")\n",
    "print(f\"  F1 Score:  {final_results['f1']:.4f}\")\n",
    "print(f\"\\nFake (0) Class:\")\n",
    "print(f\"  Precision: {final_results['fake_precision']:.4f}\")\n",
    "print(f\"  Recall:    {final_results['fake_recall']:.4f}\")\n",
    "print(f\"  F1 Score:  {final_results['fake_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(\n",
    "    final_results['labels'], \n",
    "    final_results['predictions'], \n",
    "    target_names=['Fake (0)', 'Real (1)']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(final_results['labels'], final_results['predictions'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Fake (0)', 'Real (1)'],\n",
    "            yticklabels=['Fake (0)', 'Real (1)'])\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.title('Confusion Matrix - SBiGRU-MCNN', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./confusion_matrix.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].plot(history['train_loss'], label='Train', marker='o')\n",
    "axes[0, 0].plot(history['val_loss'], label='Val', marker='s')\n",
    "axes[0, 0].set_title('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(history['train_acc'], label='Train', marker='o')\n",
    "axes[0, 1].plot(history['val_acc'], label='Val', marker='s')\n",
    "axes[0, 1].set_title('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(history['val_f1'], label='Real F1', marker='s', color='green')\n",
    "axes[1, 0].plot(history['val_fake_f1'], label='Fake F1', marker='^', color='red')\n",
    "axes[1, 0].set_title('F1 Scores')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(history['lr'], marker='o', color='purple')\n",
    "axes[1, 1].set_title('Learning Rate')\n",
    "axes[1, 1].set_yscale('log')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./training_curves.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': early_stopping.best_model_state,\n",
    "    'config': {\n",
    "        'bert_model': BERT_MODEL,\n",
    "        'max_length': MAX_LENGTH,\n",
    "        'mcnn_filters': MCNN_FILTERS,\n",
    "        'mcnn_kernel_sizes': MCNN_KERNEL_SIZES,\n",
    "        'bigru_hidden_dim': BIGRU_HIDDEN_DIM,\n",
    "        'bigru_num_layers': BIGRU_NUM_LAYERS,\n",
    "        'dropout': DROPOUT\n",
    "    },\n",
    "    'results': {\n",
    "        'accuracy': final_results['accuracy'],\n",
    "        'f1_real': final_results['f1'],\n",
    "        'f1_fake': final_results['fake_f1']\n",
    "    },\n",
    "    'scaler_params': {\n",
    "        'mean': scaler.mean_,\n",
    "        'scale': scaler.scale_\n",
    "    }\n",
    "}, MODEL_SAVE_PATH)\n",
    "\n",
    "print(f\"Model saved to: {MODEL_SAVE_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
